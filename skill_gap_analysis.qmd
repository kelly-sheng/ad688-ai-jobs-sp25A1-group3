---
title: "Skill Gap Analysis"
subtitle: "Compare the skills required in IT job postings against the actual skills of group members to identify knowledge gaps and areas for improvement"
title-block-banner: "#008f7a"
---

# Loading Libraries and Data
```{python}
from pyspark.sql import SparkSession
import pandas as pd
import matplotlib.pyplot as plt

raw_df = pd.read_csv("data/lightcast_job_postings.csv")
#raw_df.columns.tolist()
```

# Cleaning Data
```{python}
columns_to_drop = [
    "ID", "URL", "ACTIVE_URLS", "DUPLICATES", "LAST_UPDATED_TIMESTAMP",
    "NAICS2", "NAICS3", "NAICS4", "NAICS5", "NAICS6",
    "SOC_2", "SOC_3", "SOC_5"
]
raw_df.drop(columns=columns_to_drop, inplace=True)

# Fill missing values
raw_df["SALARY"].fillna(raw_df["SALARY"].median(), inplace=True)
raw_df["NAICS_2022_6"].fillna("Unknown", inplace=True)

# Drop columns with >50% missing values
raw_df.dropna(thresh=len(raw_df) * 0.5, axis=1, inplace=True)

raw_df = raw_df.drop_duplicates(subset=["TITLE", "COMPANY", "LOCATION", "POSTED"], keep="first")

#raw_df.head()
```

# Create a team-based skill dataframe

 Use Scale (1-5) to indicate proficiency levels for each team Member: 

- 1 = Beginner
- 2 = Basic knowledge
- 3 = Intermediate
- 4 = Advanced
- 5 = Expert

**Note:** We build the team skill dataframe based on our skills and the most in-demand IT skills and set 1-5 levels for each team member. This allows us to compare side by side in the comparation analysis below.

```{python}
import pandas as pd

skills_data = {
    "Name": ["Mackenzie", "Sabrina", "Kelly"],
    "Communication": [4, 4, 4],
    "Data Analysis": [2, 3, 4],
    "Management": [4, 2, 3],
    "SQL (Programming Language)": [2, 4, 4],
    "Problem Solving": [3, 4, 4],
    "Leadership": [4, 4, 3],
    "Computer Science": [1, 3, 1],
    "Operations": [2, 1, 2],
    "Project Management": [2, 2, 2],
    "Business Process": [2, 3, 3],
    "Business Requirements": [3, 1, 2],
    "Excel": [3, 2, 5],
    "Finance": [1, 2, 3],
    "Python (Programming Language)": [2, 3, 3],
    "Detail Oriented": [5, 4, 3],
    "SAP Applications": [4, 3, 1],
    "Dashboard": [4, 4, 1],
    "Presentations": [5, 3, 2],
    "Tableau (Business Intelligence Software)": [4, 5, 3],
    "Planning": [4, 3, 3]
}

df_skills = pd.DataFrame(skills_data)
df_skills.set_index("Name", inplace=True)
df_skills

#--- Plot -----

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
sns.heatmap(df_skills, annot=True, cmap="coolwarm", linewidths=0.5, vmin=1, vmax=5)
plt.title("Team Skill Levels Heatmap")
plt.yticks(rotation=0)    # keep names horizontal
plt.tight_layout()
plt.savefig("output/team_skills_heatmap.png", dpi=300)
plt.show()
plt.close()

```

The team skills levels headmap demostrated we are strogest in communication and problem solving. We also solid in SQL, dashboard /Tableau, and finance. Our weak spots are Computer Science, operations, project management, and writing clear business requiments and process steps. 

## Top strengths per person** 

```{python}
top_strengths = df_skills.apply(lambda row: row[row == row.max()].index.tolist(), axis=1)
top_strengths.to_frame(name="Top Strength Skills")

```

## Team averages by skill

```{python}
team_avg = df_skills.mean().sort_values(ascending=False)
team_avg.to_frame(name="Team Average (1–5)")

```

# Compare team skills to industry requirements

## Extract the Most In-Demand Skills from IT Job Postings 

```{python}
from collections import Counter
import ast
import pandas as pd

#  Parse SKILLS_NAME into Python lists
raw_df["SKILLS_NAME"] = raw_df["SKILLS_NAME"].apply(
    lambda x: ast.literal_eval(x) if isinstance(x, str) and x.strip().startswith("[") else (x if isinstance(x, list) else [])
)

# rename things so similar ones match and stay consistent

alias_map = {
    "SQL": "SQL (Programming Language)",
    "Sql": "SQL (Programming Language)",
    "MS Excel": "Excel",
    "Microsoft Excel": "Excel",
    "PowerBI": "Power BI",
}
def canon_skill(s: str) -> str:
    s = s.strip()
    return alias_map.get(s, s)

# 3) Combines and count
all_skills = [canon_skill(s) for sublist in raw_df["SKILLS_NAME"] for s in (sublist if isinstance(sublist, list) else []) if isinstance(s, str)]
skill_counts = Counter([s for s in all_skills if s])

# 4) Top Skills 
top_skills = [skill for skill, _ in skill_counts.most_common(20)]
print("Top skills (dataset):", top_skills)

```


## Industry expertise demand (data-driven 1–5)

In this section, We built a simple market target for each top skill using what employers write in job postings. First, we joined the job title and description so we could read the text. If a post listed MIN_YEARS_EXPERIENCE, we used it; if not, we pulled numbers like “3+ years” from the text and mapped years to a 1–5 level (with a small bump so “3 years” sits in the middle of a 3–5 range). Next, we read seniority words in the title (junior vs. senior/lead/manager) and skill phrases in the text (basic, intermediate, advanced, expert) and turned those into levels too. For each posting and skill, we combined the three signals, years (50%), seniority (30%), and phrases (20%) to get one score. Finally, we averaged those scores across all postings for each skill to get a 1–5 industry target, which we used to compare with our team’s ratings.

```{python}
import re
import numpy as np

# Build text fields if they exist; otherwise empty strings
title_col = "TITLE" if "TITLE" in raw_df.columns else None
body_col  = "BODY"  if "BODY"  in raw_df.columns else None

text_title = raw_df[title_col].astype(str).str.lower() if title_col else ""
text_body  = raw_df[body_col].astype(str).str.lower()  if body_col  else ""
text_all   = (text_title + " " + text_body).astype(str).str.strip()

# Prefer MIN_YEARS_EXPERIENCE if present; else parse "3+ years" from text
min_col = "MIN_YEARS_EXPERIENCE" if "MIN_YEARS_EXPERIENCE" in raw_df.columns else None
min_years = pd.to_numeric(raw_df[min_col], errors="coerce") if min_col else pd.Series(np.nan, index=raw_df.index)

def extract_years_from_text(text):
    if not isinstance(text, str): return np.nan
    m = re.search(r'(\d+)\s*\+?\s*(?:years?|yrs)\s+(?:of\s+)?experience', text, flags=re.I)
    return float(m.group(1)) if m else np.nan

years_from_text = text_all.apply(extract_years_from_text)
years_req = min_years.where(min_years.notna(), years_from_text)

def years_to_level_from_min(y):
    if pd.isna(y): return np.nan
    y = float(y)
    base = 1 if y < 1 else 2 if y < 2 else 3 if y < 4 else 4 if y < 6 else 5
    return min(5, base + 0.3)  # small bump so "3 years" ≈ mid of typical 3–5

years_level = years_req.apply(years_to_level_from_min)

def seniority_from_title(t):
    if not isinstance(t, str): return np.nan
    if re.search(r'\b(intern|junior|jr|entry)\b', t):             return 2
    if re.search(r'\b(senior|sr|lead|principal|architect)\b', t): return 5
    if re.search(r'\b(manager|director|head)\b', t):              return 5
    return 3

seniority_level = text_title.apply(seniority_from_title) if title_col else pd.Series(np.nan, index=raw_df.index)

PHRASE_LEVELS = [
    (r'\b(expert|expertise|mastery|guru)\b', 5),
    (r'\b(advanced|in-depth|strong|proficient|hands-on|solid)\b', 4),
    (r'\b(intermediate|working knowledge)\b', 3),
    (r'\b(basic|knowledge of|familiarity)\b', 2),
]
def phrase_level(text):
    if not isinstance(text, str): return np.nan
    lvl = np.nan
    for pat, v in PHRASE_LEVELS:
        if re.search(pat, text):
            lvl = v if pd.isna(lvl) else max(lvl, v)
    return lvl

phrase_level_series = text_all.apply(phrase_level)

# Explode one row per (posting, skill), keep only Top 20 skills
exploded = pd.DataFrame({
    "SKILLS_LIST": raw_df["SKILLS_NAME"],
    "years_level": years_level,
    "seniority_level": seniority_level,
    "phrase_level": phrase_level_series
}).explode("SKILLS_LIST")

exploded["SKILL"] = exploded["SKILLS_LIST"].astype(str).apply(canon_skill)
exploded = exploded[exploded["SKILL"].isin(top_skills)]

# Combine signals → expected level per row
w_years, w_seniority, w_phrase = 0.5, 0.3, 0.2
def combine_levels(row):
    vals, wts = [], []
    if pd.notna(row["years_level"]):     vals.append(row["years_level"]);     wts.append(w_years)
    if pd.notna(row["seniority_level"]): vals.append(row["seniority_level"]); wts.append(w_seniority)
    if pd.notna(row["phrase_level"]):    vals.append(row["phrase_level"]);    wts.append(w_phrase)
    if not vals: return 3.0
    return float(np.average(vals, weights=wts))

exploded["EXPECTED_LEVEL"] = exploded.apply(combine_levels, axis=1)

# Final per-skill target (1–5)
expected_per_skill = (
    exploded.groupby("SKILL")["EXPECTED_LEVEL"]
            .mean()
            .clip(1,5)
            .round(2)
            .reindex(top_skills)
)
expected_per_skill.name = "Target (Data-Driven)"
expected_per_skill
```


## Team Skills Vs. Industry Requiments 
```{python}
# If df_skills already exists, this will use it; else create a minimal placeholder
if "df_skills" not in globals():
    df_skills = pd.DataFrame({
        "Name": ["Kel","Mak","Maria"],
        **{s: [2,2,2] for s in top_skills} 
    }).set_index("Name")

# Make sure all top_skills are present as numeric 0–5
for s in top_skills:
    if s not in df_skills.columns:
        df_skills[s] = 0

df_team_top10 = (
    df_skills[top_skills]
      .apply(pd.to_numeric, errors="coerce")
      .fillna(0).clip(0,5)
)

# Build comparison frame
industry_expectations_dd = pd.DataFrame(
    [expected_per_skill.values],
    index=["Industry Expectation (Data-Driven)"],
    columns=expected_per_skill.index
)
comparison_df_dd = pd.concat([df_team_top10, industry_expectations_dd])
comparison_df_dd

```

```{python}
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))
sns.heatmap(comparison_df_dd, annot=True, cmap="YlGnBu", linewidths=0.5, vmin=0, vmax=5)
plt.title("Team vs. Industry Expertise Demand (Top 20 Skills) — Data-Driven Targets")
plt.yticks(rotation=0)
plt.tight_layout()
plt.savefig("output/team_vs_Industry_expertise_demand_skills_heatmap.png", dpi=300)
plt.show()
plt.close()

```

The team vs. industry headmad compares our skills to the market targets (bottom row). We meet or beat the target in communication and Tableau and are close on problem solving, Excel, and detail-oriented work. We are below the target in computer science, operations, project management, business requirements/process, leadership, finance, Python, and SQL. Our focus should be to raise those areas to about 3.5 or 4 with short courses and practice. Overall, we explain and show insights well, but we need stronger basics and delivery skills to match the market. 

## Gaps + Market Adjusted Priorities

```{python}
# Unweighted gap (Target − Team Avg)
team_avg = df_team_top10.mean()
gap = expected_per_skill - team_avg

gap_table = (
    pd.DataFrame({
        "Avg Team Level": team_avg.round(2),
        "Target (Data-Driven)": expected_per_skill.round(2),
        "Gap (Target − Avg)": gap.round(2)
    })
    .sort_values("Gap (Target − Avg)", ascending=False)
)
gap_table


```

The gaps table shows where we sit below the market target. Positive numbers mean we need to improve; negative numbers mean we already meet or beat the target. Our biggest gaps are in computer science, operations, business requirements, project management, and finance. Smaller gaps show up in SAP, business process, and Python. We already match or exceed the market in communication, Tableau, and being detail-oriented.

To set priorities, we adjust each gap by how common the skill is in job postings (market-adjusted priority). Using that, we should first focus on computer science and operations, then business requirements and project management, followed by finance/SAP. This plan lets us close the largest, most market-relevant gaps first while keeping our strengths sharp.


# Improvement Plan 

To improve our IT skills, we can focus on computer science basics, business requirements, project management, and operations. Mackenzie can prioritize computer science, then operations, finance, and project management. Sabrina will focus on project management, business requirements, and operations. Finally, Kelly can focus on computer science, then business requirements, operations, and SAP basics. We can keep our strengths, such as communication, Tableau, SQL, and problem-solving, refreshed with light weekly practice.

Additionally, we could use the following resources to improve our skills: Harvard CS50x for an introduction to computer science (a free course) and LeetCode for practice. For the programming languages SQL and Python, we can use Coursera and DataCamp courses, and LeetCode for programming exercises, which are really helpful for interview practice. For Project Management and operations, we can take the Google Project Management on Coursera. For business requirements, we can take the Managing Requirements for the Business Analysis course on Pluralsight. For finance, we can use Khan Academy’s accounting and financial statements modules. For SAP, we can use SAP Learning’s free fundamentals. For Excel, we can follow Microsoft Learn’s Excel path to reach level 3+.

Finally, we can address our skill gaps with a simple schedule. We can meet weekly or every other week and rotate knowledge guides for each session. If someone is great at project management or another skill, they will share their knowledge and tips. We will work on small, practical projects where we code together, review each other’s work, and discuss what we find. We can keep a shared document and a simple dashboard using a template to track each person’s goals, progress, and next steps for each area that needs improvement. After each session, we will note what we learned, what held us back, and what went well to keep improving.


