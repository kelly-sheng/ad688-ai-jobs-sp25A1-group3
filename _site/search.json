[
  {
    "objectID": "data_analysis.html",
    "href": "data_analysis.html",
    "title": "Data Analysis",
    "section": "",
    "text": "1 Loading Libraries and Data\n\nfrom pyspark.sql import SparkSession\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nraw_df = pd.read_csv(\"data/lightcast_job_postings.csv\")\nraw_df.columns.tolist()\n\n/var/folders/mw/hvx6c2015337qp08y2pvrxm80000gn/T/ipykernel_36620/4224945869.py:5: DtypeWarning: Columns (19,30) have mixed types. Specify dtype option on import or set low_memory=False.\n  raw_df = pd.read_csv(\"data/lightcast_job_postings.csv\")\n\n\n['ID',\n 'LAST_UPDATED_DATE',\n 'LAST_UPDATED_TIMESTAMP',\n 'DUPLICATES',\n 'POSTED',\n 'EXPIRED',\n 'DURATION',\n 'SOURCE_TYPES',\n 'SOURCES',\n 'URL',\n 'ACTIVE_URLS',\n 'ACTIVE_SOURCES_INFO',\n 'TITLE_RAW',\n 'BODY',\n 'MODELED_EXPIRED',\n 'MODELED_DURATION',\n 'COMPANY',\n 'COMPANY_NAME',\n 'COMPANY_RAW',\n 'COMPANY_IS_STAFFING',\n 'EDUCATION_LEVELS',\n 'EDUCATION_LEVELS_NAME',\n 'MIN_EDULEVELS',\n 'MIN_EDULEVELS_NAME',\n 'MAX_EDULEVELS',\n 'MAX_EDULEVELS_NAME',\n 'EMPLOYMENT_TYPE',\n 'EMPLOYMENT_TYPE_NAME',\n 'MIN_YEARS_EXPERIENCE',\n 'MAX_YEARS_EXPERIENCE',\n 'IS_INTERNSHIP',\n 'SALARY',\n 'REMOTE_TYPE',\n 'REMOTE_TYPE_NAME',\n 'ORIGINAL_PAY_PERIOD',\n 'SALARY_TO',\n 'SALARY_FROM',\n 'LOCATION',\n 'CITY',\n 'CITY_NAME',\n 'COUNTY',\n 'COUNTY_NAME',\n 'MSA',\n 'MSA_NAME',\n 'STATE',\n 'STATE_NAME',\n 'COUNTY_OUTGOING',\n 'COUNTY_NAME_OUTGOING',\n 'COUNTY_INCOMING',\n 'COUNTY_NAME_INCOMING',\n 'MSA_OUTGOING',\n 'MSA_NAME_OUTGOING',\n 'MSA_INCOMING',\n 'MSA_NAME_INCOMING',\n 'NAICS2',\n 'NAICS2_NAME',\n 'NAICS3',\n 'NAICS3_NAME',\n 'NAICS4',\n 'NAICS4_NAME',\n 'NAICS5',\n 'NAICS5_NAME',\n 'NAICS6',\n 'NAICS6_NAME',\n 'TITLE',\n 'TITLE_NAME',\n 'TITLE_CLEAN',\n 'SKILLS',\n 'SKILLS_NAME',\n 'SPECIALIZED_SKILLS',\n 'SPECIALIZED_SKILLS_NAME',\n 'CERTIFICATIONS',\n 'CERTIFICATIONS_NAME',\n 'COMMON_SKILLS',\n 'COMMON_SKILLS_NAME',\n 'SOFTWARE_SKILLS',\n 'SOFTWARE_SKILLS_NAME',\n 'ONET',\n 'ONET_NAME',\n 'ONET_2019',\n 'ONET_2019_NAME',\n 'CIP6',\n 'CIP6_NAME',\n 'CIP4',\n 'CIP4_NAME',\n 'CIP2',\n 'CIP2_NAME',\n 'SOC_2021_2',\n 'SOC_2021_2_NAME',\n 'SOC_2021_3',\n 'SOC_2021_3_NAME',\n 'SOC_2021_4',\n 'SOC_2021_4_NAME',\n 'SOC_2021_5',\n 'SOC_2021_5_NAME',\n 'LOT_CAREER_AREA',\n 'LOT_CAREER_AREA_NAME',\n 'LOT_OCCUPATION',\n 'LOT_OCCUPATION_NAME',\n 'LOT_SPECIALIZED_OCCUPATION',\n 'LOT_SPECIALIZED_OCCUPATION_NAME',\n 'LOT_OCCUPATION_GROUP',\n 'LOT_OCCUPATION_GROUP_NAME',\n 'LOT_V6_SPECIALIZED_OCCUPATION',\n 'LOT_V6_SPECIALIZED_OCCUPATION_NAME',\n 'LOT_V6_OCCUPATION',\n 'LOT_V6_OCCUPATION_NAME',\n 'LOT_V6_OCCUPATION_GROUP',\n 'LOT_V6_OCCUPATION_GROUP_NAME',\n 'LOT_V6_CAREER_AREA',\n 'LOT_V6_CAREER_AREA_NAME',\n 'SOC_2',\n 'SOC_2_NAME',\n 'SOC_3',\n 'SOC_3_NAME',\n 'SOC_4',\n 'SOC_4_NAME',\n 'SOC_5',\n 'SOC_5_NAME',\n 'LIGHTCAST_SECTORS',\n 'LIGHTCAST_SECTORS_NAME',\n 'NAICS_2022_2',\n 'NAICS_2022_2_NAME',\n 'NAICS_2022_3',\n 'NAICS_2022_3_NAME',\n 'NAICS_2022_4',\n 'NAICS_2022_4_NAME',\n 'NAICS_2022_5',\n 'NAICS_2022_5_NAME',\n 'NAICS_2022_6',\n 'NAICS_2022_6_NAME']\n\n\n\n\n2 Cleaning Data\n\ncolumns_to_drop = [\n    \"ID\", \"URL\", \"ACTIVE_URLS\", \"DUPLICATES\", \"LAST_UPDATED_TIMESTAMP\",\n    \"NAICS2\", \"NAICS3\", \"NAICS4\", \"NAICS5\", \"NAICS6\",\n    \"SOC_2\", \"SOC_3\", \"SOC_5\"\n]\nraw_df.drop(columns=columns_to_drop, inplace=True)\n\n# Fill missing values\nraw_df[\"SALARY\"].fillna(raw_df[\"SALARY\"].median(), inplace=True)\nraw_df[\"NAICS_2022_6\"].fillna(\"Unknown\", inplace=True)\n\n# Drop columns with &gt;50% missing values\nraw_df.dropna(thresh=len(raw_df) * 0.5, axis=1, inplace=True)\n\nraw_df = raw_df.drop_duplicates(subset=[\"TITLE\", \"COMPANY\", \"LOCATION\", \"POSTED\"], keep=\"first\")\n\nraw_df.head()\n\n/var/folders/mw/hvx6c2015337qp08y2pvrxm80000gn/T/ipykernel_36620/2034363739.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  raw_df[\"SALARY\"].fillna(raw_df[\"SALARY\"].median(), inplace=True)\n/var/folders/mw/hvx6c2015337qp08y2pvrxm80000gn/T/ipykernel_36620/2034363739.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  raw_df[\"NAICS_2022_6\"].fillna(\"Unknown\", inplace=True)\n/var/folders/mw/hvx6c2015337qp08y2pvrxm80000gn/T/ipykernel_36620/2034363739.py:10: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n  raw_df[\"NAICS_2022_6\"].fillna(\"Unknown\", inplace=True)\n\n\n\n\n\n\n\n\n\nLAST_UPDATED_DATE\nPOSTED\nEXPIRED\nDURATION\nSOURCE_TYPES\nSOURCES\nTITLE_RAW\nBODY\nMODELED_EXPIRED\nMODELED_DURATION\n...\nNAICS_2022_2\nNAICS_2022_2_NAME\nNAICS_2022_3\nNAICS_2022_3_NAME\nNAICS_2022_4\nNAICS_2022_4_NAME\nNAICS_2022_5\nNAICS_2022_5_NAME\nNAICS_2022_6\nNAICS_2022_6_NAME\n\n\n\n\n0\n9/6/2024\n6/2/2024\n6/8/2024\n6.0\n[\\n \"Company\"\\n]\n[\\n \"brassring.com\"\\n]\nEnterprise Analyst (II-III)\n31-May-2024\\n\\nEnterprise Analyst (II-III)\\n\\n...\n6/8/2024\n6.0\n...\n44.0\nRetail Trade\n441.0\nMotor Vehicle and Parts Dealers\n4413.0\nAutomotive Parts, Accessories, and Tire Retailers\n44133.0\nAutomotive Parts and Accessories Retailers\n441330.0\nAutomotive Parts and Accessories Retailers\n\n\n1\n8/2/2024\n6/2/2024\n8/1/2024\nNaN\n[\\n \"Job Board\"\\n]\n[\\n \"maine.gov\"\\n]\nOracle Consultant - Reports (3592)\nOracle Consultant - Reports (3592)\\n\\nat SMX i...\n8/1/2024\nNaN\n...\n56.0\nAdministrative and Support and Waste Managemen...\n561.0\nAdministrative and Support Services\n5613.0\nEmployment Services\n56132.0\nTemporary Help Services\n561320.0\nTemporary Help Services\n\n\n2\n9/6/2024\n6/2/2024\n7/7/2024\n35.0\n[\\n \"Job Board\"\\n]\n[\\n \"dejobs.org\"\\n]\nData Analyst\nTaking care of people is at the heart of every...\n6/10/2024\n8.0\n...\n52.0\nFinance and Insurance\n524.0\nInsurance Carriers and Related Activities\n5242.0\nAgencies, Brokerages, and Other Insurance Rela...\n52429.0\nOther Insurance Related Activities\n524291.0\nClaims Adjusting\n\n\n3\n9/6/2024\n6/2/2024\n7/20/2024\n48.0\n[\\n \"Job Board\"\\n]\n[\\n \"disabledperson.com\",\\n \"dejobs.org\"\\n]\nSr. Lead Data Mgmt. Analyst - SAS Product Owner\nAbout this role:\\n\\nWells Fargo is looking for...\n6/12/2024\n10.0\n...\n52.0\nFinance and Insurance\n522.0\nCredit Intermediation and Related Activities\n5221.0\nDepository Credit Intermediation\n52211.0\nCommercial Banking\n522110.0\nCommercial Banking\n\n\n4\n6/19/2024\n6/2/2024\n6/17/2024\n15.0\n[\\n \"FreeJobBoard\"\\n]\n[\\n \"craigslist.org\"\\n]\nComisiones de $1000 - $3000 por semana... Comi...\nComisiones de $1000 - $3000 por semana... Comi...\n6/17/2024\n15.0\n...\n99.0\nUnclassified Industry\n999.0\nUnclassified Industry\n9999.0\nUnclassified Industry\n99999.0\nUnclassified Industry\n999999.0\nUnclassified Industry\n\n\n\n\n5 rows × 109 columns\n\n\n\n\n\n3 Plot setup for AI vs Non-AI job posting count\n\nimport os, re\nimport pandas as pd\n\n# Kelly’s cleaned dataframe must exist\nassert \"raw_df\" in globals(), \"raw_df must exist (Kelly’s cleaned dataframe).\"\ndf = raw_df.copy()\n\n# Parse date -&gt; month\nif \"POSTED\" not in df.columns:\n    raise ValueError(\"Expected a POSTED column in raw_df.\")\ndf[\"POSTED_DT\"] = pd.to_datetime(df[\"POSTED\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"POSTED_DT\"])\ndf[\"month\"] = df[\"POSTED_DT\"].dt.to_period(\"M\").dt.to_timestamp()\n\n# Combine likely text fields\ncandidate_text_cols = [\n    \"TITLE\",\"TITLE_CLEAN\",\"TITLE_NAME\",\"BODY\",\n    \"SKILLS\",\"SKILLS_NAME\",\n    \"SPECIALIZED_SKILLS\",\"SPECIALIZED_SKILLS_NAME\",\n    \"SOFTWARE_SKILLS\",\"SOFTWARE_SKILLS_NAME\",\n    \"COMMON_SKILLS\",\"COMMON_SKILLS_NAME\",\n    \"CERTIFICATIONS_NAME\",\n]\ntext_cols = [c for c in candidate_text_cols if c in df.columns]\nif not text_cols:\n    text_cols = [\"TITLE\"] if \"TITLE\" in df.columns else []\ntext_series = (\n    df[text_cols].astype(str).agg(\" \".join, axis=1).str.lower()\n    if text_cols else pd.Series([\"\"] * len(df), index=df.index)\n)\n\n# ✅ FIXED list (no cut-off strings)\nai_terms = [\n    \"artificial intelligence\",\"ai\",\"machine learning\",\"deep learning\",\n    \"neural network\",\"nlp\",\"natural language\",\"computer vision\",\n    \"reinforcement learning\",\"generative ai\",\"llm\",\"gpt\",\"chatgpt\",\n    \"transformer\",\"bert\",\"prompt engineer\",\"prompt engineering\"\n]\n\n# Word-boundary pattern so we don't match 'retail' for 'ai'\nai_pattern = re.compile(\n    r\"\\b(?:\"\n    + \"|\".join(re.escape(t) for t in ai_terms)\n    + r\")\\b\",\n    flags=re.IGNORECASE,\n)\n\ndf[\"IS_AI\"] = text_series.str.contains(ai_pattern, na=False)\n\n# Monthly counts\nmonthly = (\n    df.groupby([\"month\",\"IS_AI\"])\n      .size()\n      .unstack(fill_value=0)\n      .rename(columns={True: \"AI\", False: \"Non-AI\"})\n      .sort_index()\n)\n\nmonthly_plt = monthly.copy()\nmonthly_plt.head(12)\n\n\n\n\n\n\n\nIS_AI\nNon-AI\nAI\n\n\nmonth\n\n\n\n\n\n\n2024-05-01\n12460\n1503\n\n\n2024-06-01\n11462\n2263\n\n\n2024-07-01\n8463\n3720\n\n\n2024-08-01\n10619\n3977\n\n\n2024-09-01\n10148\n4582\n\n\n\n\n\n\n\n\n\n4 Job Postings for AI vs Non-AI Jobs\n\nimport os\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import FuncFormatter\n\nassert \"monthly_plt\" in globals(), \"Run the setup chunk first.\"\n\nos.makedirs(\"output\", exist_ok=True)\n\nplt.figure(figsize=(12, 6))\nplt.plot(monthly_plt.index, monthly_plt[\"AI\"],     marker=\"o\", linewidth=2, label=\"AI jobs\")\nplt.plot(monthly_plt.index, monthly_plt[\"Non-AI\"], marker=\"o\", linewidth=2, label=\"Non-AI jobs\")\nplt.title(\"AI vs Non-AI Job Postings Over Time (Monthly)\")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of Job Postings\")\nplt.gca().yaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{int(x):,}\"))\nplt.grid(True, alpha=0.25)\nplt.legend()\nplt.tight_layout()\nplt.savefig(\"output/ai_vs_nonai_over_time.png\", dpi=200, bbox_inches=\"tight\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n5 Prep for monthly AI counts\n\nimport os, re\nimport numpy as np\nimport pandas as pd\n\nassert \"raw_df\" in globals(), \"raw_df must exist.\"\n\ndf = raw_df.copy()\n\n# ---- Dates -&gt; month ----\ndf[\"POSTED_DT\"] = pd.to_datetime(df[\"POSTED\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"POSTED_DT\"])\ndf[\"month\"] = df[\"POSTED_DT\"].dt.to_period(\"M\").dt.to_timestamp()\n\n# ---- AI detector (reuse if already present) ----\nif \"IS_AI\" not in df.columns:\n    ai_terms = [\n        \"artificial intelligence\",\"ai\",\"machine learning\",\"deep learning\",\n        \"neural network\",\"nlp\",\"natural language\",\"computer vision\",\n        \"reinforcement learning\",\"generative ai\",\"llm\",\"gpt\",\"chatgpt\",\n        \"transformer\",\"bert\",\"prompt engineer\",\"prompt engineering\"\n    ]\n    text_cols = [c for c in [\n        \"TITLE\",\"TITLE_CLEAN\",\"BODY\",\n        \"SKILLS\",\"SKILLS_NAME\",\n        \"SPECIALIZED_SKILLS\",\"SPECIALIZED_SKILLS_NAME\",\n        \"SOFTWARE_SKILLS\",\"SOFTWARE_SKILLS_NAME\",\n        \"COMMON_SKILLS\",\"COMMON_SKILLS_NAME\",\n        \"CERTIFICATIONS_NAME\"\n    ] if c in df.columns]\n    combined = (df[text_cols].astype(str).agg(\" \".join, axis=1).str.lower()\n                if text_cols else pd.Series([\"\"], index=df.index))\n    pattern = re.compile(r\"\\b(?:%s)\\b\" % \"|\".join(re.escape(t) for t in ai_terms), re.I)\n    df[\"IS_AI\"] = combined.str.contains(pattern, na=False)\n\n# ---- Pick the best available industry label ----\nind_candidates = [\n    \"NAICS_2022_6_NAME\",\"NAICS6_NAME\",\n    \"NAICS_2022_4_NAME\",\"NAICS4_NAME\",\n    \"NAICS_2022_2_NAME\",\"NAICS2_NAME\",\n    \"NAICS_2022_6\",\"NAICS6\"\n]\nIND_COL = next((c for c in ind_candidates if c in df.columns), None)\nif IND_COL is None:\n    raise ValueError(\"No NAICS/industry name/code columns found.\")\n\n# ---- Monthly AI counts per industry ----\nai = df[df[\"IS_AI\"]].copy()\nai_monthly = (\n    ai.groupby([IND_COL, \"month\"])\n      .size()\n      .reset_index(name=\"count\")\n)\n\n# ---- Compute growth: (last 3-mo avg - first 3-mo avg) / first 3-mo avg ----\ndef growth_row(g):\n    g = g.sort_values(\"month\")\n    k = min(3, len(g))\n    first = g[\"count\"].iloc[:k].mean()\n    last  = g[\"count\"].iloc[-k:].mean()\n    total = g[\"count\"].sum()\n    if k &lt; 2 or first == 0:\n        return pd.Series({\"growth_pct\": np.nan, \"first_avg\": first, \"last_avg\": last, \"months\": len(g), \"total\": total})\n    return pd.Series({\"growth_pct\": (last - first) / first * 100.0,\n                      \"first_avg\": first, \"last_avg\": last,\n                      \"months\": len(g), \"total\": total})\n\ngrowth_df = ai_monthly.groupby(IND_COL).apply(growth_row).reset_index()\n\n# filter out tiny-volume industries to avoid wild % changes\nMIN_TOTAL = 30\ngrowth_df = growth_df[growth_df[\"total\"] &gt;= MIN_TOTAL].dropna(subset=[\"growth_pct\"])\n\n# pick top movers (you can adjust top_n)\ntop_n = 12\ngrowth_top = growth_df.sort_values(\"growth_pct\", ascending=False).head(top_n)\n\n# Save a copy if you want a table in the doc\ngrowth_top_rounded = growth_top.copy()\ngrowth_top_rounded[\"growth_pct\"] = growth_top_rounded[\"growth_pct\"].round(1)\ngrowth_top_rounded.head(top_n)\n\n/var/folders/mw/hvx6c2015337qp08y2pvrxm80000gn/T/ipykernel_36620/1460438954.py:67: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  growth_df = ai_monthly.groupby(IND_COL).apply(growth_row).reset_index()\n\n\n\n\n\n\n\n\n\nNAICS_2022_6_NAME\ngrowth_pct\nfirst_avg\nlast_avg\nmonths\ntotal\n\n\n\n\n260\nOffices of Other Holding Companies\n372.7\n3.666667\n17.333333\n5.0\n56.0\n\n\n300\nOther Motor Vehicle Parts Manufacturing\n330.8\n4.333333\n18.666667\n5.0\n68.0\n\n\n358\nResearch and Development in the Physical, Engi...\n176.2\n14.000000\n38.666667\n5.0\n133.0\n\n\n137\nExecutive Search Services\n160.0\n6.666667\n17.333333\n5.0\n59.0\n\n\n80\nComputer and Computer Peripheral Equipment and...\n154.5\n3.666667\n9.333333\n5.0\n33.0\n\n\n406\nTemporary Help Services\n148.8\n42.333333\n105.333333\n5.0\n352.0\n\n\n189\nHuman Resources Consulting Services\n125.6\n13.000000\n29.333333\n5.0\n96.0\n\n\n296\nOther Management Consulting Services\n116.4\n46.666667\n101.000000\n5.0\n337.0\n\n\n427\nWholesale Trade Agents and Brokers\n109.5\n7.000000\n14.666667\n5.0\n52.0\n\n\n325\nPharmaceutical Preparation Manufacturing\n108.0\n8.333333\n17.333333\n5.0\n62.0\n\n\n280\nOther Computer Related Services\n103.8\n70.666667\n144.000000\n5.0\n509.0\n\n\n415\nUnclassified Industry\n101.8\n280.666667\n566.333333\n5.0\n2025.0\n\n\n\n\n\n\n\n\n\n6 AI-Driven Job Growth by Industry\n\n# --- Short, readable labels + plot & save (Option B) -------------------------\nimport os, re\nfrom textwrap import shorten\nimport matplotlib.pyplot as plt\n\n# Use your existing industry column if defined; otherwise default:\nIND_COL = IND_COL if \"IND_COL\" in globals() else \"NAICS_2022_6_NAME\"\n\ndef short_label(s: str) -&gt; str:\n    s = str(s)\n    # Common abbreviations to keep labels compact but clear\n    s = re.sub(r'(?i)\\bservices?\\b', 'Svcs', s)\n    s = re.sub(r'(?i)\\bmanufacturing\\b', 'Mfg', s)\n    s = re.sub(r'(?i)\\bpreparation\\b', 'Prep', s)\n    s = re.sub(r'(?i)\\bmanagement\\b', 'Mgmt', s)\n    s = re.sub(r'(?i)\\bcomputer\\b', 'Comp', s)\n    s = re.sub(r'(?i)\\bequipment\\b', 'Equip', s)\n    s = re.sub(r'(?i)\\bwholesale\\b', 'Whsl', s)\n    s = re.sub(r'(?i)\\bagents?\\b', 'Agts', s)\n    s = re.sub(r'(?i)\\bscientific\\b', 'Sci', s)\n    s = re.sub(r'(?i)\\bengineering\\b', 'Eng', s)\n    s = re.sub(r'(?i)\\band\\b', '&', s)\n    s = re.sub(r'(?i)\\bother\\b\\s*', '', s)  # drop leading \"Other\"\n    # Final safe trim\n    return shorten(s.strip(), width=32, placeholder='…')\n\nplot_df = growth_top.copy()\nplot_df[\"label\"] = plot_df[IND_COL].astype(str).map(short_label)\n\nfig, ax = plt.subplots(figsize=(11, 7))\nbars = ax.barh(plot_df[\"label\"], plot_df[\"growth_pct\"], color=\"#2F6DB3\", edgecolor=\"black\")\nax.invert_yaxis()  # biggest at top\n\nax.set_title(\"AI Job Posting Growth by Industry (First vs Last Month)\", fontsize=16)\nax.set_xlabel(\"Growth (%)\", fontsize=12)\nax.set_ylabel(\"Industry\", fontsize=12)\nax.grid(axis=\"x\", alpha=0.25)\n\n# Value labels\nfor b in bars:\n    w = b.get_width()\n    ax.text(\n        w + (1 if w &gt;= 0 else -1),\n        b.get_y() + b.get_height() / 2,\n        f\"{w:.1f}%\",\n        va=\"center\",\n        ha=\"left\" if w &gt;= 0 else \"right\",\n        fontsize=10,\n    )\n\nplt.tight_layout()\nos.makedirs(\"output\", exist_ok=True)\nplt.savefig(\"output/ai_industry_growth_shortlabels.png\", dpi=200, bbox_inches=\"tight\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n7 Non-AI Job Posting Growth by Industry setup\n\nimport os, re\nimport pandas as pd\nfrom textwrap import shorten\n\nassert \"raw_df\" in globals(), \"raw_df must exist (your cleaned dataframe).\"\ndf = raw_df.copy()\n\n# Pick an industry-name column that exists\nIND_COL = next((c for c in [\n    \"NAICS_2022_6_NAME\",\"NAICS6_NAME\",\"NAICS_2022_4_NAME\",\"NAICS4_NAME\",\n    \"NAICS_2022_2_NAME\",\"NAICS2_NAME\"\n] if c in df.columns), None)\nassert IND_COL, \"No industry/NAICS name column found.\"\n\nTITLE_COL = \"TITLE_CLEAN\" if \"TITLE_CLEAN\" in df.columns else \"TITLE\"\nassert TITLE_COL in df.columns, \"Need a TITLE or TITLE_CLEAN column.\"\n\n# Dates → month\ndf[\"POSTED_DT\"] = pd.to_datetime(df[\"POSTED\"], errors=\"coerce\")\ndf = df.dropna(subset=[\"POSTED_DT\", IND_COL])\ndf[\"month\"] = df[\"POSTED_DT\"].dt.to_period(\"M\").dt.to_timestamp()\n\n# Detect AI vs non-AI via title keywords\nAI_TERMS = [\n    \"artificial intelligence\", r\"\\bAI\\b\", \"machine learning\", r\"\\bML\\b\",\n    \"deep learning\", r\"\\bLLM\\b\", r\"\\bNLP\\b\", \"computer vision\",\n    \"generative\", \"chatgpt\", r\"gpt-\\d+\", \"transformer\", \"bert\",\n    \"prompt engineer\", \"reinforcement learning\"\n]\nai_pat = re.compile(\"|\".join(AI_TERMS), flags=re.IGNORECASE)\nif \"is_ai\" not in df.columns:\n    df[\"is_ai\"] = df[TITLE_COL].astype(str).str.contains(ai_pat, na=False)\n\n# Use industries from your AI-growth visual if available; otherwise pick top 10 by AI postings last month\nif \"growth_top\" in globals():\n    target_inds = [str(x) for x in growth_top[IND_COL].dropna().tolist()]\nelse:\n    last_m = df[\"month\"].max()\n    ai_last = (df[df[\"is_ai\"] & (df[\"month\"] == last_m)]\n               .groupby(IND_COL).size().sort_values(ascending=False).head(10))\n    target_inds = ai_last.index.astype(str).tolist()\n\n# Build non-AI growth (% first→last month) for those industries\nnon_ai = df[(~df[\"is_ai\"]) & (df[IND_COL].astype(str).isin(target_inds))].copy()\nmonthly = (non_ai.groupby([IND_COL, \"month\"]).size().reset_index(name=\"count\"))\n\nfirst_last = (monthly.sort_values(\"month\")\n                     .groupby(IND_COL, as_index=False)\n                     .agg(first=(\"count\",\"first\"), last=(\"count\",\"last\")))\nfirst_last = first_last[first_last[\"first\"] &gt; 0].copy()\nfirst_last[\"growth_pct\"] = ((first_last[\"last\"] - first_last[\"first\"])\n                            / first_last[\"first\"]) * 100.0\nfirst_last = first_last[first_last[IND_COL].astype(str).isin(target_inds)]\n\ndef short_label(s: str) -&gt; str:\n    s = str(s)\n    s = re.sub(r'(?i)\\bservices?\\b', 'Svcs', s)\n    s = re.sub(r'(?i)\\bmanufacturing\\b', 'Mfg', s)\n    s = re.sub(r'(?i)\\bmanagement\\b', 'Mgmt', s)\n    s = re.sub(r'(?i)\\bpreparation\\b', 'Prep', s)\n    s = re.sub(r'(?i)\\bcomputer\\b', 'Comp', s)\n    s = re.sub(r'(?i)\\bequipment\\b', 'Equip', s)\n    s = re.sub(r'(?i)\\bwholesale\\b', 'Whsl', s)\n    s = re.sub(r'(?i)\\band\\b', '&', s)\n    s = re.sub(r'\\s+', ' ', s).strip()\n    return shorten(s, width=32, placeholder='…')\n\nnon_ai_growth_plot_df = (first_last\n                         .sort_values(\"growth_pct\", ascending=False)\n                         .assign(label=lambda d: d[IND_COL].map(short_label)))\n\nos.makedirs(\"output\", exist_ok=True)\nnon_ai_growth_plot_df.head(10)  # preview table\n\n\n\n\n\n\n\n\nNAICS_2022_6_NAME\nfirst\nlast\ngrowth_pct\nlabel\n\n\n\n\n8\nResearch and Development in the Physical, Engi...\n45\n114\n153.333333\nResearch & Development in the…\n\n\n6\nOther Motor Vehicle Parts Manufacturing\n12\n22\n83.333333\nOther Motor Vehicle Parts Mfg\n\n\n1\nExecutive Search Services\n37\n58\n56.756757\nExecutive Search Svcs\n\n\n0\nComputer and Computer Peripheral Equipment and...\n16\n22\n37.500000\nComp & Comp Peripheral Equip &…\n\n\n5\nOther Management Consulting Services\n162\n195\n20.370370\nOther Mgmt Consulting Svcs\n\n\n3\nOffices of Other Holding Companies\n23\n25\n8.695652\nOffices of Other Holding…\n\n\n9\nTemporary Help Services\n272\n288\n5.882353\nTemporary Help Svcs\n\n\n10\nUnclassified Industry\n2028\n2025\n-0.147929\nUnclassified Industry\n\n\n2\nHuman Resources Consulting Services\n32\n31\n-3.125000\nHuman Resources Consulting Svcs\n\n\n7\nPharmaceutical Preparation Manufacturing\n61\n58\n-4.918033\nPharmaceutical Prep Mfg\n\n\n\n\n\n\n\n\n\n8 Non-AI Job Posting Growth by Industry\n\nimport os\nimport matplotlib.pyplot as plt\n\n# If prep didn't run in this kernel, rebuild quickly\nif \"non_ai_growth_plot_df\" not in globals():\n    # Re-run a minimal rebuild using the same logic\n    assert \"raw_df\" in globals(), \"raw_df is required to rebuild plot data.\"\n    # You can just execute the prep cell above; keeping this here for resilience:\n    # (We simply import the name if it exists; otherwise advise to run prep.)\n    raise AssertionError(\"Run the prep chunk first to create non_ai_growth_plot_df.\")\n\ndfp = non_ai_growth_plot_df.copy()\n\nif dfp.empty:\n    print(\"non_ai_growth_plot_df is empty—nothing to plot. \"\n          \"Check that selected industries have non-AI rows in the first/last month.\")\nelse:\n    os.makedirs(\"output\", exist_ok=True)\n    colors = dfp[\"growth_pct\"].ge(0).map({True: \"#1f77b4\", False: \"#d62728\"}).to_numpy()\n\n    fig, ax = plt.subplots(figsize=(11, 7))\n    bars = ax.barh(dfp[\"label\"], dfp[\"growth_pct\"], color=colors, edgecolor=\"black\")\n\n    ax.axvline(0, color=\"black\", linewidth=1, alpha=0.6)\n    ax.invert_yaxis()\n    ax.set_title(\"Non-AI Job Posting Growth by Industry (First → Last Month)\", fontsize=16)\n    ax.set_xlabel(\"Growth (%)\")\n    ax.set_ylabel(\"Industry\")\n    ax.grid(axis=\"x\", alpha=0.25)\n\n    for b, v in zip(bars, dfp[\"growth_pct\"]):\n        ax.text(\n            v + (1 if v &gt;= 0 else -1),\n            b.get_y() + b.get_height() / 2,\n            f\"{v:.1f}%\",\n            va=\"center\",\n            ha=\"left\" if v &gt;= 0 else \"right\",\n            fontsize=10,\n        )\n\n    plt.tight_layout()\n    plt.savefig(\"output/non_ai_growth_pct_in_ai_growth_industries_colored.png\",\n                dpi=200, bbox_inches=\"tight\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n9 AI-powered roles vs non-ai roles salary prep\n\nimport os, re\nimport numpy as np\nimport pandas as pd\n\nassert \"raw_df\" in globals(), \"raw_df (cleaned dataframe) must exist.\"\n\ndf = raw_df.copy()\n\n# --- Pick columns robustly ---\nTITLE_COL = \"TITLE_CLEAN\" if \"TITLE_CLEAN\" in df.columns else \"TITLE\"\nassert TITLE_COL in df.columns, \"Need a TITLE or TITLE_CLEAN column.\"\n\nIND_COL = next((c for c in [\n    \"NAICS_2022_6_NAME\",\"NAICS6_NAME\",\"NAICS_2022_4_NAME\",\"NAICS4_NAME\",\n    \"NAICS_2022_2_NAME\",\"NAICS2_NAME\",\"LIGHTCAST_SECTORS_NAME\"\n] if c in df.columns), None)\nassert IND_COL, \"No industry/NAICS name column found.\"\n\n# Salary: prefer SALARY; otherwise average of FROM/TO if present\nsal = pd.to_numeric(df.get(\"SALARY\", np.nan), errors=\"coerce\")\nif sal.isna().all() and {\"SALARY_FROM\",\"SALARY_TO\"} &lt;= set(df.columns):\n    s_from = pd.to_numeric(df[\"SALARY_FROM\"], errors=\"coerce\")\n    s_to   = pd.to_numeric(df[\"SALARY_TO\"],   errors=\"coerce\")\n    sal = (s_from + s_to) / 2\ndf[\"salary_num\"] = pd.to_numeric(sal, errors=\"coerce\")\n\n# keep positive salaries only\ndf = df[df[\"salary_num\"] &gt; 0].copy()\n\n# Optional: cap extreme outliers so a few posts don't dominate the mean\nq_low, q_hi = df[\"salary_num\"].quantile([0.01, 0.99])\ndf[\"salary_num\"] = df[\"salary_num\"].clip(q_low, q_hi)\n\n# --- Tag AI vs non-AI using title keywords ---\nAI_TERMS = [\n    \"artificial intelligence\", r\"\\bAI\\b\", \"machine learning\", r\"\\bML\\b\",\n    \"deep learning\", r\"\\bLLM\\b\", r\"\\bNLP\\b\", \"computer vision\",\n    \"generative\", \"chatgpt\", r\"gpt-\\d+\", \"transformer\", r\"\\bbert\\b\",\n    \"prompt engineer\", \"reinforcement learning\", \"data scientist\", \"ai engineer\"\n]\nai_pat = re.compile(\"|\".join(AI_TERMS), flags=re.IGNORECASE)\ndf[\"is_ai\"] = df[TITLE_COL].astype(str).str.contains(ai_pat, na=False)\n\n# --- Find top industries by AI posting count (choose N)\nN = 10\nai_counts = (df[df[\"is_ai\"]]\n             .groupby(IND_COL, dropna=True)\n             .size()\n             .sort_values(ascending=False)\n             .head(N)\n             .rename(\"ai_posts\")\n             .reset_index())\ntop_inds = ai_counts[IND_COL].astype(str).tolist()\n\n# --- Compute average salary (AI vs non-AI) for those industries\nsubset = df[df[IND_COL].astype(str).isin(top_inds)].copy()\ngrp = subset.groupby([IND_COL, \"is_ai\"])[\"salary_num\"].agg([\"mean\", \"count\"]).reset_index()\n\nai_part  = grp[grp[\"is_ai\"]].rename(columns={\"mean\":\"avg_ai_salary\", \"count\":\"ai_postings\"})\nnon_part = grp[~grp[\"is_ai\"]].rename(columns={\"mean\":\"avg_nonai_salary\", \"count\":\"non_ai_postings\"})\n\nai_vs_trad_industry_salary = (\n    ai_counts[[IND_COL, \"ai_posts\"]]        # preserves AI-based ordering\n    .merge(ai_part[[IND_COL, \"avg_ai_salary\", \"ai_postings\"]], on=IND_COL, how=\"left\")\n    .merge(non_part[[IND_COL, \"avg_nonai_salary\", \"non_ai_postings\"]], on=IND_COL, how=\"left\")\n)\n\n# Clean up & preview\nai_vs_trad_industry_salary = ai_vs_trad_industry_salary.fillna(0)\nos.makedirs(\"output\", exist_ok=True)\nai_vs_trad_industry_salary.head(N)\n\n\n\n\n\n\n\n\nNAICS_2022_6_NAME\nai_posts\navg_ai_salary\nai_postings\navg_nonai_salary\nnon_ai_postings\n\n\n\n\n0\nAll Other Miscellaneous Food Manufacturing\n124\n125106.451613\n124\n108667.836735\n49\n\n\n1\nComputer Systems Design Services\n81\n120464.666667\n81\n123184.301252\n4073\n\n\n2\nEmployment Placement Agencies\n72\n117815.555556\n72\n113490.867107\n4244\n\n\n3\nDirect Health and Medical Insurance Carriers\n67\n102811.940299\n67\n116431.746753\n1386\n\n\n4\nUnclassified Industry\n57\n129006.070175\n57\n113253.334609\n9148\n\n\n5\nOther Computer Related Services\n53\n117909.245283\n53\n118771.586707\n1309\n\n\n6\nAdministrative Management and General Manageme...\n52\n156290.384615\n52\n133606.945132\n4447\n\n\n7\nOffices of Certified Public Accountants\n48\n116174.354167\n48\n130229.120365\n1645\n\n\n8\nSoftware Publishers\n35\n95534.285714\n35\n131028.541624\n973\n\n\n9\nCommercial Banking\n34\n145390.588235\n34\n120671.148515\n1919\n\n\n\n\n\n\n\n\n\n10 AI-powered Roles Salaries vs. Non-AI Roles Salaries\n\nimport os, re\nimport matplotlib.pyplot as plt\nfrom textwrap import shorten\nfrom matplotlib.ticker import FuncFormatter\n\nassert \"ai_vs_trad_industry_salary\" in globals(), \"Run the prep chunk first.\"\n\ndfp = ai_vs_trad_industry_salary.copy()\nif dfp.empty:\n    print(\"No data to plot after filtering. Check AI detection or industry column.\")\nelse:\n    # shorten very long industry labels\n    def short_label(s: str) -&gt; str:\n        s = str(s)\n        s = re.sub(r'(?i)\\bservices?\\b', 'Svcs', s)\n        s = re.sub(r'(?i)\\bmanufacturing\\b', 'Mfg', s)\n        s = re.sub(r'(?i)\\bmanagement\\b', 'Mgmt', s)\n        s = re.sub(r'(?i)\\bcomputer\\b', 'Comp', s)\n        s = re.sub(r'(?i)\\bequipment\\b', 'Equip', s)\n        s = re.sub(r'\\s+', ' ', s).strip()\n        return shorten(s, width=36, placeholder='…')\n\n    dfp[\"label\"] = dfp[IND_COL].map(short_label)\n\n    x = range(len(dfp))\n    w = 0.38\n\n    fig, ax = plt.subplots(figsize=(14, 7))\n    b1 = ax.bar([i - w/2 for i in x], dfp[\"avg_ai_salary\"],    width=w, label=\"AI job posts\",     edgecolor=\"black\")\n    b2 = ax.bar([i + w/2 for i in x], dfp[\"avg_nonai_salary\"], width=w, label=\"Non-AI job posts\", edgecolor=\"black\")\n\n    ax.set_title(\"Average Salary — AI vs. Non-AI Posts in Top AI Industries\", fontsize=16)\n    ax.set_xlabel(\"Industry (Top by AI Posting Volume)\")\n    ax.set_ylabel(\"Average Salary ($)\")\n    ax.set_xticks(list(x))\n    ax.set_xticklabels(dfp[\"label\"], rotation=35, ha=\"right\")\n    ax.yaxis.set_major_formatter(FuncFormatter(lambda v, pos: f\"${int(v):,}\"))\n    ax.grid(axis=\"y\", alpha=0.25)\n    ax.legend()\n\n    # annotate bars\n    for bars in (b1, b2):\n        for p in bars:\n            h = p.get_height()\n            if h &gt; 0:\n                ax.text(p.get_x()+p.get_width()/2, h, f\"${int(h):,}\",\n                        ha=\"center\", va=\"bottom\", fontsize=9)\n\n    plt.tight_layout()\n    os.makedirs(\"output\", exist_ok=True)\n    plt.savefig(\"output/ai_vs_nonai_avg_salary_by_industry.png\", dpi=200, bbox_inches=\"tight\")\n    plt.show()"
  },
  {
    "objectID": "research_introduction.html",
    "href": "research_introduction.html",
    "title": "AI vs. Non-AI Careers",
    "section": "",
    "text": "We live in a time when artificial intelligence (AI) is changing the way people work. Across industries, tasks that were once done by humans are being automated, while new opportunities are appearing that require different skills. In 2024, this topic is especially important because AI tools are no longer limited to technology companies—they are now widely used in healthcare, education, energy, retail, and many other sectors. Understanding how AI affects the job market helps prepare for shifts in employment, salary trends, and the creation of new professions."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]